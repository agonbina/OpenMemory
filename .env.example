# ============================================
# OpenMemory - Environment Configuration
# ============================================

# --------------------------------------------
# Backend Server Settings
# --------------------------------------------
OM_PORT=8080

# API Authentication (IMPORTANT: Set a strong API key for production!)
# Generate a secure key: openssl rand -base64 32
# Leave empty to disable authentication (development only)
OM_API_KEY=your-secret-api-key-here

# Rate Limiting
# Enable rate limiting to prevent abuse
OM_RATE_LIMIT_ENABLED=true
# Time window in milliseconds (default: 60000 = 1 minute)
OM_RATE_LIMIT_WINDOW_MS=60000
# Maximum requests per window (default: 100 requests per minute)
OM_RATE_LIMIT_MAX_REQUESTS=100

# Optional: Log all authenticated requests (set to 'true' for debugging)
OM_LOG_AUTH=false

# Server Mode
OM_MODE=standard # standard | langgraph

# --------------------------------------------
# Metadata Store
# --------------------------------------------
# sqlite (default) | postgres
OM_METADATA_BACKEND=sqlite
OM_DB_PATH=./data/openmemory.sqlite

# PostgreSQL Settings (used when OM_METADATA_BACKEND=postgres or OM_VECTOR_BACKEND=pgvector)
OM_PG_HOST=localhost
OM_PG_PORT=5432
OM_PG_DB=openmemory
OM_PG_USER=postgres
OM_PG_PASSWORD=postgres
OM_PG_SCHEMA=public
OM_PG_TABLE=openmemory_memories
OM_PG_SSL=disable # disable | require

# --------------------------------------------
# Vector Store Backend
# --------------------------------------------
# sqlite (default) | pgvector | weaviate
OM_VECTOR_BACKEND=sqlite
OM_VECTOR_TABLE=openmemory_vectors
OM_WEAVIATE_URL=
OM_WEAVIATE_API_KEY=
OM_WEAVIATE_CLASS=OpenMemory

# --------------------------------------------
# Embeddings Configuration
# --------------------------------------------
# Available providers: openai, gemini, ollama, local, synthetic
# Embedding models per sector can be configured in models.yaml
#
# NOTE: Your selected TIER (fast/smart/deep) affects how embeddings work:
# • FAST tier: Uses synthetic embeddings regardless of OM_EMBEDDINGS setting
# • SMART tier: Combines synthetic + compressed semantic from your chosen provider
# • DEEP tier: Uses full embeddings from your chosen provider
#
# For SMART/DEEP tiers, set your preferred provider:
OM_EMBEDDINGS=openai

# Vector dimension (auto-adjusted by tier, but can be overridden)
# • FAST: 256-dim  • SMART: 384-dim  • DEEP: 1536-dim
# OM_VEC_DIM=1536

# Embedding Mode
# simple   = 1 unified batch call for all sectors (faster, rate-limit safe, recommended)
# advanced = 5 separate calls, one per sector (higher precision, more API calls)
OM_EMBED_MODE=simple

# Advanced Mode Options (only used when OM_EMBED_MODE=advanced)
# Enable parallel embedding (not recommended for Gemini due to rate limits)
OM_ADV_EMBED_PARALLEL=false
# Delay between embeddings in milliseconds
OM_EMBED_DELAY_MS=200

# OpenAI-compatible Embeddings Provider
# OM_OPENAI_BASE_URL=https://api.openai.com/v1
# Model override for all sector embeddings (leave empty to use defaults)
# OM_OPENAI_MODEL=text-embedding-qwen3-embedding-4b

# API Configuration
# Max request body size in bytes (default: 1MB)
OM_MAX_PAYLOAD_SIZE=1000000

# --------------------------------------------
# Embedding Provider API Keys
# --------------------------------------------
# OpenAI Embeddings
OPENAI_API_KEY=your-openai-api-key-here

# Google Gemini Embeddings
GEMINI_API_KEY=your-gemini-api-key-here

# Ollama Local Embeddings
OLLAMA_URL=http://localhost:11434

# Local Model Path (for custom embedding models)
LOCAL_MODEL_PATH=/path/to/your/local/model

# --------------------------------------------
# Memory System Settings
# --------------------------------------------

# ============================================
# PERFORMANCE TIER (Auto-detected or Manual)
# ============================================
# OpenMemory automatically detects your hardware and selects the optimal tier.
# You can override this by setting OM_TIER manually.
#
# Available Tiers:
#
# FAST  - Synthetic embeddings only (256-dim)
#         • Recall: ~70-75%  • QPS: 700-850  • RAM: 0.6GB/10k memories
#         • Best for: Local apps, VS Code extensions, low-end hardware
#         • Auto-selected: < 4 CPU cores or < 8GB RAM
#
# SMART - Hybrid embeddings (256-dim synthetic + 128-dim compressed semantic = 384-dim)
#         • Recall: ~85%  • QPS: 500-600  • RAM: 0.9GB/10k memories
#         • Best for: Production servers, AI copilots, mid-range hardware
#         • Auto-selected: 4-7 CPU cores and 8-15GB RAM
#
# DEEP  - Full AI embeddings (1536-dim OpenAI/Gemini)
#         • Recall: ~95-100%  • QPS: 350-400  • RAM: 1.6GB/10k memories
#         • Best for: Cloud deployments, high-accuracy systems, research
#         • Auto-selected: 8+ CPU cores and 16+ GB RAM
#
# Leave commented to auto-detect, or set manually:
# OM_TIER=fast
# OM_TIER=smart
# OM_TIER=deep

OM_MIN_SCORE=0.3
OM_DECAY_LAMBDA=0.02

# Decay interval in minutes
# Testing: 0.5 (30s) for rapid benchmarks
# Development: 5 (5min) for realistic decay testing
# Production: 10 (10min) for optimal throughput (3% batch = less disk pressure)
# Recommended: 5-10 minutes to balance decay accuracy vs overhead
OM_DECAY_INTERVAL_MINUTES=10

# Decay ratio (percentage of memories to decay per run, 0.01-0.1)
# Lower = more stable variance, higher = faster decay propagation
OM_DECAY_RATIO=0.03

# Sleep between segment processing (ms) to avoid lock contention
OM_DECAY_SLEEP_MS=200

# Full Semantic Graph MVP Settings
# Use summary-only storage (≤300 chars, intelligent extraction)
OM_USE_SUMMARY_ONLY=true
# Maximum summary length - smart extraction preserves dates, names, numbers, actions
OM_SUMMARY_MAX_LENGTH=300
# Memories per segment (10k recommended for optimal cache performance)
OM_SEG_SIZE=10000

# Cache segments (auto-tuned by tier, but can be overridden)
# • FAST: 2 segments  • SMART: 3 segments  • DEEP: 5 segments
# OM_CACHE_SEGMENTS=3

# Max active queries (auto-tuned by tier, but can be overridden)
# • FAST: 32 queries  • SMART: 64 queries  • DEEP: 128 queries
# OM_MAX_ACTIVE=64

# Brain Sector Configuration (auto-classified, but you can override)
# Sectors: episodic, semantic, procedural, emotional, reflective

# Auto-Reflection System
# Automatically creates reflective memories by clustering similar memories
OM_AUTO_REFLECT=false
# Reflection interval in minutes (default: 10)
OM_REFLECT_INTERVAL=10
# Minimum memories required before reflection runs (default: 20)
OM_REFLECT_MIN_MEMORIES=20

# Compression
# Enable automatic content compression for large memories
OM_COMPRESSION_ENABLED=false
# Minimum content length (characters) to trigger compression (default: 100)
OM_COMPRESSION_MIN_LENGTH=100
# Compression algorithm: semantic, syntactic, aggressive, auto (default: auto)
OM_COMPRESSION_ALGORITHM=auto

# --------------------------------------------
# LangGraph Integration Mode (LGM)
# --------------------------------------------
OM_LG_NAMESPACE=default
OM_LG_MAX_CONTEXT=50
OM_LG_REFLECTIVE=true